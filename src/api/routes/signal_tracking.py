"""
Signal Tracking API Routes for FastAPI

This module provides API endpoints for tracking trading signals generated by confluence analysis.
Supports real-time P&L monitoring, signal lifecycle management, and dashboard integration.
"""

from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import JSONResponse
from typing import Dict, Any, List, Optional
import time
import uuid
import logging
from datetime import datetime, timedelta
import yaml
from pathlib import Path

# Initialize router
router = APIRouter()

# Configure logging
logger = logging.getLogger(__name__)

# Load configuration to check if signal tracking is enabled
def is_signal_tracking_enabled() -> bool:
    """Check if signal tracking is enabled in configuration."""
    try:
        config_path = Path("config/config.yaml")
        if config_path.exists():
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
                return config.get('signal_tracking', {}).get('enabled', True)
    except Exception as e:
        logger.error(f"Error reading signal tracking config: {e}")
    return True  # Default to enabled if config can't be read

# In-memory storage for active signals (in production, use Redis or database)
active_signals: Dict[str, Dict[str, Any]] = {}
signal_history: List[Dict[str, Any]] = []

# Configuration
SIGNAL_EXPIRY_HOURS = 24  # Signals expire after 24 hours
MAX_HISTORY_SIZE = 1000   # Keep last 1000 signals in history

def cleanup_expired_signals():
    """Remove expired signals from active tracking."""
    current_time = time.time()
    expired_ids = []
    
    for signal_id, signal_data in active_signals.items():
        created_time = signal_data.get('created_at', 0)
        if current_time - created_time > (SIGNAL_EXPIRY_HOURS * 3600):
            expired_ids.append(signal_id)
    
    for signal_id in expired_ids:
        expired_signal = active_signals.pop(signal_id)
        # Move to history
        expired_signal['status'] = 'expired'
        expired_signal['ended_at'] = current_time
        signal_history.append(expired_signal)
        
        # Maintain history size limit
        if len(signal_history) > MAX_HISTORY_SIZE:
            signal_history.pop(0)
    
    if expired_ids:
        logger.info(f"Cleaned up {len(expired_ids)} expired signals")

@router.get("/active")
async def get_active_signals():
    """Get all currently active trading signals."""
    try:
        # Check if signal tracking is enabled
        if not is_signal_tracking_enabled():
            logger.debug("Signal tracking disabled - returning empty signals list")
            return JSONResponse({
                "success": True,
                "signals": [],
                "count": 0,
                "message": "Signal tracking disabled"
            })
        
        cleanup_expired_signals()
        
        # Convert to list and add current P&L calculations
        signals_list = []
        for signal_id, signal_data in active_signals.items():
            signal_copy = signal_data.copy()
            signal_copy['id'] = signal_id
            
            # Add duration
            current_time = time.time()
            duration_seconds = current_time - signal_data.get('created_at', current_time)
            signal_copy['duration_seconds'] = int(duration_seconds)
            signal_copy['duration_formatted'] = format_duration(duration_seconds)
            
            signals_list.append(signal_copy)
        
        return JSONResponse({
            "success": True,
            "signals": signals_list,
            "count": len(signals_list)
        })
        
    except Exception as e:
        logger.error(f"Error fetching active signals: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error fetching signals: {str(e)}")

@router.delete("/tracked/{signal_id}")
async def stop_tracking_signal(signal_id: str):
    """Stop tracking a specific signal."""
    try:
        if signal_id not in active_signals:
            raise HTTPException(status_code=404, detail="Signal not found")
        
        # Move signal to history
        signal_data = active_signals.pop(signal_id)
        signal_data['status'] = 'stopped'
        signal_data['ended_at'] = time.time()
        signal_history.append(signal_data)
        
        # Maintain history size limit
        if len(signal_history) > MAX_HISTORY_SIZE:
            signal_history.pop(0)
        
        logger.info(f"Stopped tracking signal: {signal_id}")
        
        return JSONResponse({
            "success": True,
            "message": f"Stopped tracking signal {signal_id}"
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error stopping signal tracking: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error stopping tracking: {str(e)}")

@router.post("/track")
async def add_signal_for_tracking(signal_data: Dict[str, Any]):
    """Add a new trading signal for tracking."""
    try:
        # Check if signal tracking is enabled
        if not is_signal_tracking_enabled():
            logger.debug("Signal tracking disabled - rejecting new signal")
            return JSONResponse({
                "success": False,
                "message": "Signal tracking disabled",
                "tracking_id": None
            })
        
        # Validate required fields
        required_fields = ['symbol', 'action', 'entry_price']
        for field in required_fields:
            if field not in signal_data:
                raise HTTPException(status_code=400, detail=f"Missing required field: {field}")
        
        # Generate unique tracking ID
        tracking_id = str(uuid.uuid4())
        
        # Prepare signal for storage
        tracked_signal = {
            'symbol': signal_data['symbol'],
            'action': signal_data['action'].upper(),
            'entry_price': float(signal_data['entry_price']),
            'current_price': float(signal_data['entry_price']),  # Initialize with entry price
            'confidence': signal_data.get('confidence', 0),
            'confluence_score': signal_data.get('confluence_score', 0),
            'quantity': signal_data.get('quantity', 1.0),
            'source': signal_data.get('source', 'unknown'),
            'metadata': signal_data.get('metadata', {}),
            'created_at': time.time(),
            'status': 'active',
            'pnl_usd': 0.0,
            'pnl_percentage': 0.0
        }
        
        # Store in active signals
        active_signals[tracking_id] = tracked_signal
        
        logger.info(f"Added signal for tracking: {tracking_id} - {signal_data['symbol']} {signal_data['action']}")
        
        return JSONResponse({
            "success": True,
            "tracking_id": tracking_id,
            "message": "Signal added for tracking"
        })
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error adding signal for tracking: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error adding signal: {str(e)}")

@router.get("/history")
async def get_signal_history(limit: int = Query(50, ge=1, le=500)):
    """Get historical signal data."""
    try:
        # Return most recent signals first
        recent_history = signal_history[-limit:] if len(signal_history) > limit else signal_history
        recent_history.reverse()  # Most recent first
        
        return JSONResponse({
            "success": True,
            "signals": recent_history,
            "count": len(recent_history),
            "total_history": len(signal_history)
        })
        
    except Exception as e:
        logger.error(f"Error fetching signal history: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error fetching history: {str(e)}")

@router.get("/stats")
async def get_tracking_statistics():
    """Get signal tracking statistics."""
    try:
        cleanup_expired_signals()
        
        # Calculate statistics
        total_active = len(active_signals)
        total_history = len(signal_history)
        
        # Analyze active signals
        active_long_signals = sum(1 for s in active_signals.values() if s['action'] == 'LONG')
        active_short_signals = sum(1 for s in active_signals.values() if s['action'] == 'SHORT')
        
        # Analyze historical performance
        profitable_signals = sum(1 for s in signal_history if s.get('pnl_percentage', 0) > 0)
        losing_signals = sum(1 for s in signal_history if s.get('pnl_percentage', 0) < 0)
        
        win_rate = (profitable_signals / total_history * 100) if total_history > 0 else 0
        
        stats = {
            "active_signals": {
                "total": total_active,
                "long_signals": active_long_signals,
                "short_signals": active_short_signals
            },
            "historical_performance": {
                "total_signals": total_history,
                "profitable_signals": profitable_signals,
                "losing_signals": losing_signals,
                "win_rate_percentage": round(win_rate, 2)
            },
            "system_info": {
                "signal_expiry_hours": SIGNAL_EXPIRY_HOURS,
                "max_history_size": MAX_HISTORY_SIZE,
                "last_cleanup": datetime.now().isoformat()
            }
        }
        
        return JSONResponse({
            "success": True,
            "statistics": stats
        })
        
    except Exception as e:
        logger.error(f"Error calculating statistics: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error calculating stats: {str(e)}")

def format_duration(seconds: float) -> str:
    """Format duration in seconds to human-readable string."""
    if seconds < 60:
        return f"{int(seconds)}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        return f"{minutes}m"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}h {minutes}m"

def add_confluence_signal(symbol: str, signal_data: Dict[str, Any]) -> Optional[str]:
    """
    Integration function for monitor.py to call when confluence analysis generates signals.
    
    Args:
        symbol: Trading symbol (e.g., 'BTC/USDT')
        signal_data: Signal data from confluence analysis
        
    Returns:
        str: Tracking ID if successful, None otherwise
    """
    try:
        # This function can be called synchronously from monitor.py
        # It adds the signal to the tracking system
        
        # Validate signal data
        if not signal_data.get('action') or signal_data.get('action') == 'NEUTRAL':
            return None
            
        # Generate tracking ID
        tracking_id = str(uuid.uuid4())
        
        # Prepare signal for storage
        tracked_signal = {
            'symbol': symbol,
            'action': signal_data['action'].upper(),
            'entry_price': float(signal_data.get('price', 0)),
            'current_price': float(signal_data.get('price', 0)),
            'confidence': signal_data.get('confidence', 0),
            'confluence_score': signal_data.get('confluence_score', 0),
            'quantity': signal_data.get('quantity', 1.0),
            'source': 'confluence_analysis',
            'metadata': signal_data.get('source_data', {}),
            'created_at': time.time(),
            'status': 'active',
            'pnl_usd': 0.0,
            'pnl_percentage': 0.0
        }
        
        # Store in active signals
        active_signals[tracking_id] = tracked_signal
        
        logger.info(f"Added confluence signal for tracking: {tracking_id}")
        return tracking_id
        
    except Exception as e:
        logger.error(f"Error adding confluence signal: {str(e)}")
        return None 