"""Bybit exchange implementation with CCXT standardization."""

import asyncio
import logging
import json
import hmac
import hashlib
import time
import os
from typing import Dict, Any, List, Optional, Callable, Tuple, ContextManager, Union
from datetime import datetime
import aiohttp
import websockets
from urllib.parse import urlencode
from pybit.unified_trading import HTTP 
from contextlib import contextmanager
from dataclasses import dataclass, field
from src.core.error.models import ErrorSeverity
import pandas as pd
import traceback
from dotenv import load_dotenv
import numpy as np
import re
from collections import defaultdict

# Load environment variables from .env file
load_dotenv()

from .base import (
    BaseExchange,
    ExchangeError,
    NetworkError,
    TimeoutError,
    AuthenticationError,
    retry_on_error,
    handle_timeout,
    RateLimitError  # Added import
)

logger = logging.getLogger(__name__)

@dataclass
class ErrorContext:
    """Context for error handling"""
    operation: str
    details: Dict[str, Any] = None
    component: str = None
    exchange: str = 'bybit'  # Set default value
    timestamp: float = field(default_factory=time.time)
    error_code: Optional[str] = None
    retry_count: int = 0

class BybitExchangeError(ExchangeError):
    """Bybit-specific exchange error"""
    pass

class InitializationError(ExchangeError):
    """Error during exchange initialization"""
    pass

class BybitExchange(BaseExchange):
    """Bybit exchange implementation with CCXT standardization"""
    
    # Class-level initialization tracking
    _instances: Dict[str, 'BybitExchange'] = {}
    _instance_lock = asyncio.Lock()
    
    @classmethod
    async def get_instance(cls, config: Dict[str, Any], error_handler: Optional[Any] = None) -> 'BybitExchange':
        """Get or create a singleton instance of BybitExchange.
        
        Args:
            config: Configuration dictionary
            error_handler: Optional error handler
            
        Returns:
            BybitExchange instance
        """
        # Use API endpoint as unique key for different environments
        instance_key = config['exchanges']['bybit']['rest_endpoint']
        
        async with cls._instance_lock:
            if instance_key not in cls._instances:
                instance = cls(config, error_handler)
                cls._instances[instance_key] = instance
                # Initialize the instance
                if not await instance.initialize():
                    logger.error("Failed to initialize BybitExchange instance")
                    del cls._instances[instance_key]
                    raise RuntimeError("Failed to initialize BybitExchange")
            return cls._instances[instance_key]
    
    ERROR_CODES = {
        '10001': 'System error',
        '10002': 'System not available',
        '10003': 'Invalid request',
        '10004': 'Invalid parameter',
        '10005': 'Operation failed',
        '10006': 'Too many requests',
        '10007': 'Authentication required',
        '10008': 'Invalid API key',
        '10009': 'Invalid signature',
    }
    
    WS_ENDPOINTS = {
        'spot': {
            'public': 'wss://stream.bybit.com/v5/public/spot',
            'private': 'wss://stream.bybit.com/v5/private'
        },
        'linear': {
            'public': 'wss://stream.bybit.com/v5/public/linear',
            'private': 'wss://stream.bybit.com/v5/private'
        },
        'inverse': {
            'public': 'wss://stream.bybit.com/v5/public/inverse',
            'private': 'wss://stream.bybit.com/v5/private'
        }
    }
    
    TIMEFRAME_MAP = {
        '1': '1',      # 1 minute
        '5': '5',      # 5 minutes
        '30': '30',    # 30 minutes
        '240': '240'   # 4 hours
    }
    
    # Add reverse mapping
    _reverse_timeframe_map = {v: k for k, v in TIMEFRAME_MAP.items()}
    
    # Add rate limit constants
    RATE_LIMITS = {
        'category': {
            'linear': {'requests': 120, 'per_second': 1},  # Category-level limit
            'spot': {'requests': 120, 'per_second': 1}
        },
        'endpoints': {
            'kline': {'requests': 120, 'per_second': 1},
            'orderbook': {'requests': 60, 'per_second': 1},
            'trades': {'requests': 60, 'per_second': 1},
            'ticker': {'requests': 60, 'per_second': 1},
            'market_data': {'requests': 120, 'per_second': 1},  # Composite limit
            'long_short_ratio': {'requests': 60, 'per_second': 1},  # New endpoint
            'risk_limits': {'requests': 60, 'per_second': 1}  # New endpoint
        }
    }
    
    def __init__(self, config: Dict[str, Any], error_handler: Optional[Any] = None):
        """Initialize Bybit exchange."""
        # Call parent init with both arguments
        super().__init__(config, error_handler)
        
        # Extract exchange specific config
        self.exchange_config = config['exchanges']['bybit']
        
        # Load environment variables first
        load_dotenv()
        
        # Set testnet mode
        self.testnet = self.exchange_config.get('testnet', False)
        
        # Initialize rate limits
        self.rate_limits = {
            'market_data': {'requests': 120, 'per_second': 1},
            'ticker': {'requests': 60, 'per_second': 1},
            'orderbook': {'requests': 60, 'per_second': 1},
            'trades': {'requests': 60, 'per_second': 1},
            'kline': {'requests': 60, 'per_second': 1},
            'long_short_ratio': {'requests': 60, 'per_second': 1},
            'risk_limits': {'requests': 60, 'per_second': 1}
        }
        
        # Initialize rate limit tracking
        self._rate_limit_timestamps = {}
        
        # Set endpoints based on testnet mode
        if self.testnet:
            self.rest_endpoint = self.exchange_config.get('testnet_endpoint', 'https://api-testnet.bybit.com')
            self.ws_endpoint = self.exchange_config['websocket'].get('testnet_endpoint', 'wss://stream-testnet.bybit.com/v5/public')
        else:
            self.rest_endpoint = self.exchange_config.get('rest_endpoint', 'https://api.bybit.com')
            self.ws_endpoint = self.exchange_config['websocket'].get('mainnet_endpoint', 'wss://stream.bybit.com/v5/public')
            
        # Load API credentials from environment variables
        self.api_key = os.getenv('BYBIT_API_KEY')
        self.api_secret = os.getenv('BYBIT_API_SECRET')
        
        # Log API key status
        self.logger = logging.getLogger(__name__)
        self.logger.info("API credentials status:")
        self.logger.debug(f"API key configured: {bool(self.api_key)}")
        self.logger.debug(f"API secret configured: {bool(self.api_secret)}")
        
        if not self.api_key or not self.api_secret:
            raise AuthenticationError(
                "Missing Bybit API credentials. Please configure via .env file or config file"
            )
        
        # Store credentials in the format expected by other methods
        self.api_credentials = {
            'api_key': self.api_key,
            'api_secret': self.api_secret
        }
        
        # Initialize websocket config
        self.ws_config = self.exchange_config.get('websocket', {})
        self.ws_channels = self.ws_config.get('channels', [])
        self.ws_symbols = self.ws_config.get('symbols', [])
        
        # Set exchange ID
        self.exchange_id = 'bybit'
        
        # Initialize WebSocket state
        self.ws = None
        self.ws_connected = False
        self.ws_subscriptions = {}
        self.ws_callbacks = {}
        self.ws_reconnect_task = None
        self.ws_keepalive_task = None
        
        self.logger.info(f"Bybit exchange initialized with endpoint: {self.rest_endpoint}")
        self.logger.info(f"WebSocket endpoint: {self.ws_endpoint}")
        
        # Mark as not initialized until async init completes
        self.initialized = False
        
        self.market_type = 'linear'  # Add default market type
        
        # Update timeframe map to match standardization
        self.timeframe_map = {
            '1': '1',
            '5': '5',
            '30': '30',
            '240': '240'
        }
        
        # Add reverse mapping
        self._reverse_timeframe_map = {v: k for k, v in self.timeframe_map.items()}
        
        self.logger.info("Bybit exchange initialized successfully")
        
        # Initialize rate limit tracking
        self._rate_limit_buckets = {
            endpoint: [] for endpoint in self.RATE_LIMITS.keys()
        }
        self._rate_limit_lock = asyncio.Lock()
        
    def _setup_basic_config(self):
        """Setup basic configuration parameters"""
        # Validate required fields
        required_fields = ['name', 'enabled', 'api_credentials']
        missing_fields = [f for f in required_fields if f not in self.exchange_config]
        if missing_fields:
            raise KeyError(f"Missing required fields in config: {missing_fields}")
        
        # Get exchange specific config
        self.market_data_config = self.exchange_config.get('market_data', {})
        
        # Get API paths
        self.market_paths = self.exchange_config.get('market_paths', {})
        
        # Initialize request tracking
        self._request_count = 0
        self._last_request_time = 0
        self.metrics_manager = None
        
        # Initialize state management
        self._initialization_lock = asyncio.Lock()
        self._initializing = False
        self._data_refresh_lock = asyncio.Lock()
        self._last_data_refresh = 0
        
        # Initialize WebSocket
        self.ws = None
        self.ws_connected = False
        self.ws_subscriptions = {}
        self.ws_callbacks = {}
        self.ws_reconnect_task = None
        self.ws_keepalive_task = None
        
        # Market data cache
        self._market_data_cache = {}
        self._cache_timestamp = 0
        self._cache_ttl = self.market_data_config.get('cache_ttl', 300)  # 5 minutes default
        
        # Set default options
        self.options.update({
            'defaultType': 'linear',
            'defaultNetwork': 'ETH',
            'networks': {
                'ETH': 'ETH',
                'BSC': 'BSC',
                'ARBITRUM': 'ARBITRUM',
            },
            'ws': {
                'ping_interval': 20,
                'ping_timeout': 10,
                'reconnect_attempts': 3,
                'reconnect_delay': 5,
            },
            'recvWindow': 5000,
            'timeDifference': 0,
            'adjustForTimeDifference': True
        })
        
        self.logger = logger
        
        # Set exchange ID
        self.exchange_id = 'bybit'
        
        # Set API URLs
        self.api_urls = {
            'public': 'https://api.bybit.com',
            'private': 'https://api.bybit.com',
            'v5': 'https://api.bybit.com/v5'
        }
        
        # Initialize supported timeframes
        self.timeframes = {
            '1m': '1',    # 1 minute
            '3m': '3',    # 3 minutes
            '5m': '5',    # 5 minutes
            '15m': '15',  # 15 minutes
            '30m': '30',  # 30 minutes
            '1h': '60',   # 1 hour
            '2h': '120',  # 2 hours
            '4h': '240',  # 4 hours
            '6h': '360',  # 6 hours
            '12h': '720', # 12 hours
            '1d': 'D',    # 1 day
            '1w': 'W',    # 1 week
            '1M': 'M'     # 1 month
        }
        
        # Initialize market type
        self._market_type = 'linear'
        
        self.timeframe_map = {
            '1': 'base',    # 1 minute - store as 'base'
            '5': 'ltf',     # 5 minutes
            '30': 'mtf',    # 30 minutes
            '240': 'htf'    # 4 hours (240 minutes)
        }
        
        # Add reverse mapping
        self._reverse_timeframe_map = {v: k for k, v in self.timeframe_map.items()}
        
        self.logger.info("Bybit exchange initialized successfully")
        
    def _create_websocket(self) -> None:
        """Create WebSocket instance."""
        try:
            if not hasattr(self, 'ws') or self.ws is None:
                self.ws = BybitWebSocket(
                    config=self.config,
                    logger=self.logger
                )
                self.logger.info("Created WebSocket instance")
            return True
        except Exception as e:
            self.logger.error(f"Error creating WebSocket instance: {str(e)}")
            return False
    
    async def _init_websocket(self) -> bool:
        """Initialize WebSocket connection."""
        try:
            if not self._create_websocket():
                return False
                
            # Connect WebSocket
            if not await self.ws.connect():
                self.logger.error("Failed to connect WebSocket")
                return False
                
            self.logger.info("WebSocket initialized successfully")
            
            # Subscribe to default channels
            for symbol in self.ws_symbols:
                await self.subscribe_market_data(symbol)
            
            return True
            
        except Exception as e:
            self.logger.error(f"WebSocket initialization failed: {str(e)}")
            return False
    
    async def initialize(self) -> bool:
        """Initialize the exchange connection."""
        try:
            self.logger.info("Initializing Bybit exchange...")
            
            if not self._validate_config(self.exchange_config):
                self.logger.error("Invalid configuration")
                return False
            
            # Initialize REST client
            self.logger.info("Initializing REST client...")
            await self._init_rest_client()
            
            # Initialize WebSocket if enabled
            if self.exchange_config.get('websocket', {}).get('enabled'):
                await self._init_websocket()
                
            self.logger.info("Bybit exchange initialized successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to initialize Bybit exchange: {str(e)}")
            return False

    def set_market_type(self, market_type: str) -> None:
        """Set and validate market type."""
        if market_type not in self.WS_ENDPOINTS:
            raise ValueError(f"Invalid market type. Must be one of {list(self.WS_ENDPOINTS.keys())}")
        self._market_type = market_type
        self.logger.info(f"Market type set to: {market_type}")

    async def _init_rest_client(self) -> bool:
        """Initialize REST client for API requests.
        
        Returns:
            bool: True if initialization successful, False otherwise
        """
        try:
            # Initialize HTTP session if not exists
            if not hasattr(self, 'session') or self.session is None:
                self.session = aiohttp.ClientSession()
            
            # Test connection with server time endpoint
            response = await self._make_request('GET', '/v5/market/time')
            if not response or 'retCode' not in response:
                self.logger.error("Failed to connect to REST API")
                return False
            
            if response['retCode'] != 0:
                self.logger.error(f"REST API error: {response.get('retMsg', 'Unknown error')}")
                return False
            
            self.logger.info("REST client initialized successfully")
            return True
        except Exception as e:
            self.logger.error(f"Error initializing REST client: {str(e)}", exc_info=True)
            return False
            
    async def _test_rest_connection(self) -> bool:
        """Test REST connection by making a simple request."""
        try:
            # Try to get server time
            response = await self._make_request('GET', '/v5/market/time')
            if response and response.get('retCode') == 0:
                return True
            return False
        except Exception as e:
            self.logger.error(f"REST connection test failed: {str(e)}")
            return False
    async def _make_request(self, method: str, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Make a request to the Bybit API.
        
        Args:
            method: HTTP method (GET, POST, etc)
            endpoint: API endpoint
            params: Request parameters
            
        Returns:
            API response as dictionary
        """
        try:
            # Normalize endpoint format
            endpoint = endpoint.lstrip('/')
            if not endpoint.startswith('v5/'):
                endpoint = f"v5/{endpoint}"
            url = f"{self.rest_endpoint}/{endpoint}"
            
            # Ensure params is a dictionary
            if params is None:
                params = {}
            
            # Check if endpoint requires authentication
            requires_auth = not endpoint.startswith(('v5/market/'))
            
            if requires_auth:
                # Add required auth params
                timestamp = str(int(time.time() * 1000))
                auth_params = {
                    'api_key': self.api_key,
                    'timestamp': timestamp,
                    'recv_window': 5000
                }
                params.update(auth_params)
                
                # Generate signature
                signature = self._generate_signature(params)
                params['sign'] = signature
                
                # Add auth headers
                headers = {
                    'X-BAPI-API-KEY': self.api_key,
                    'X-BAPI-TIMESTAMP': timestamp,
                    'X-BAPI-RECV-WINDOW': '5000',
                    'X-BAPI-SIGN': signature,
                    'Content-Type': 'application/json'
                }
            else:
                headers = {'Content-Type': 'application/json'}
            
            # Log request details safely
            safe_params = {k: '***' if k in ['api_key', 'sign'] else v 
                          for k, v in params.items()}
            self.logger.debug(f"Making request to {url}")
            self.logger.debug(f"Params: {safe_params}")
            async with aiohttp.ClientSession() as session:
                if method.upper() == 'GET':
                    async with session.get(url, params=params, headers=headers) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            self.logger.error(f"HTTP {response.status} error for {url}: {error_text}")
                            return {'retCode': -1, 'retMsg': f'HTTP {response.status} error: {error_text}'}
                            
                        try:
                            result = await response.json()
                            if not result:
                                self.logger.error("Empty response received")
                                return {'retCode': -1, 'retMsg': 'Empty response'}
                                
                            # Log concise response summary instead of full response
                            response_summary = self._summarize_response(result)
                            self.logger.debug(f"Response from {url}: {response_summary}")
                            return result
                            
                        except Exception as e:
                            self.logger.error(f"Error parsing response: {str(e)}")
                            return {'retCode': -1, 'retMsg': 'Invalid response format'}
                elif method.upper() == 'POST':
                    # For POST requests, send params as JSON in the body
                    async with session.post(url, json=params, headers=headers) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            self.logger.error(f"HTTP {response.status} error for {url}: {error_text}")
                            return {'retCode': -1, 'retMsg': f'HTTP {response.status} error: {error_text}'}
                            
                        try:
                            result = await response.json()
                            if not result:
                                self.logger.error("Empty response received")
                                return {'retCode': -1, 'retMsg': 'Empty response'}
                                
                            # Log concise response summary instead of full response
                            response_summary = self._summarize_response(result)
                            self.logger.debug(f"Response from {url}: {response_summary}")
                            return result
                            
                        except Exception as e:
                            self.logger.error(f"Error parsing response: {str(e)}")
                            return {'retCode': -1, 'retMsg': 'Invalid response format'}
                else:
                    self.logger.error(f"Unsupported HTTP method: {method}")
                    return {'retCode': -1, 'retMsg': f'Unsupported method {method}'}
                    
        except Exception as e:
            self.logger.error(f"Request error: {str(e)}")
            self.logger.debug(traceback.format_exc())
            return {'retCode': -1, 'retMsg': str(e)}

    def _get_auth_headers(self, endpoint: str, params: dict) -> dict:
        """Get authentication headers for request."""
        timestamp = int(time.time() * 1000)
        signature = self._generate_signature(timestamp, endpoint, params)
        
        return {
            'X-BAPI-API-KEY': self.api_key,
            'X-BAPI-TIMESTAMP': str(timestamp),
            'X-BAPI-SIGN': signature,
        }
        
    def _generate_signature(self, params: Dict[str, Any]) -> str:
        """Generate signature for authentication."""
        # Sort parameters alphabetically
        sorted_params = dict(sorted(params.items()))
        
        # Convert parameters to query string
        query_string = urlencode(sorted_params)
        
        # Create signature
        signature = hmac.new(
            self.api_secret.encode(),
            query_string.encode(),
            hashlib.sha256
        ).hexdigest()
        
        return signature
        
    def _summarize_response(self, response: Union[Dict, List]) -> str:
        """Create a summary of the response for logging purposes.
        
        Args:
            response: The API response to summarize
            
        Returns:
            A concise summary of the response
        """
        try:
            if isinstance(response, dict):
                # For dictionary responses
                ret_code = response.get('retCode', 'N/A')
                ret_msg = response.get('retMsg', 'N/A')
                
                # Check if there's a result field and summarize it
                result = response.get('result', {})
                result_summary = "None"
                
                if isinstance(result, dict):
                    keys = list(result.keys())
                    if 'list' in result and isinstance(result['list'], list):
                        list_len = len(result['list'])
                        sample = str(result['list'][0])[:50] + "..." if list_len > 0 else "[]"
                        result_summary = f"{{list: [{list_len} items, sample: {sample}]}}"
                    else:
                        result_summary = f"{{keys: {keys}}}"
                elif isinstance(result, list):
                    list_len = len(result)
                    sample = str(result[0])[:50] + "..." if list_len > 0 else "[]"
                    result_summary = f"[{list_len} items, sample: {sample}]"
                
                return f"{{retCode: {ret_code}, retMsg: {ret_msg}, result: {result_summary}}}"
            
            elif isinstance(response, list):
                # For list responses
                list_len = len(response)
                sample = str(response[0])[:50] + "..." if list_len > 0 else "[]"
                return f"[{list_len} items, sample: {sample}]"
            
            else:
                return f"{type(response).__name__}: {str(response)[:100]}"
        
        except Exception as e:
            return f"Error summarizing response: {str(e)}"

    async def connect_ws(self) -> bool:
        """Connect to Bybit WebSocket with proper configuration"""
        try:
            # Get config with protocol validation
            ws_config = self.config.get('websocket', {})
            if not ws_config.get('enabled', False):
                self.logger.info("WebSocket is disabled in config")
                return False

            # Get the correct endpoint from config
            if self.config.get('testnet', False):
                ws_url = ws_config.get('testnet_endpoint')
                self.logger.debug(f"Using testnet WebSocket endpoint: {ws_url}")
            else:
                ws_url = ws_config.get('mainnet_endpoint')
                self.logger.debug(f"Using mainnet WebSocket endpoint: {ws_url}")

            if not ws_url:
                self.logger.error("WebSocket endpoint not configured")
                return False

            # Validate URL format
            if not ws_url.startswith('wss://'):
                ws_url = f"wss://{ws_url.lstrip('/')}"

            # Ensure URL has correct format for v5 API
            if not '/v5/public/linear' in ws_url:
                base_url = ws_url.rstrip('/')
                if base_url.endswith('/v5/public'):
                    ws_url = f"{base_url}/linear"
                elif not base_url.endswith('/v5/public/linear'):
                    ws_url = f"{base_url}/v5/public/linear"

            self.logger.info(f"Connecting to WebSocket URL: {ws_url}")
            
            # Add connection timeout
            timeout = aiohttp.ClientTimeout(total=10)
            session = aiohttp.ClientSession(timeout=timeout)
            self.ws = await session.ws_connect(
                ws_url,
                autoclose=False,
                heartbeat=30
            )
            self.connected = True
            self.logger.info("WebSocket connected successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"WebSocket connection failed: {str(e)}")
            if hasattr(self, 'ws') and self.ws:
                await self.ws.close()
            if hasattr(self, 'session') and self.session:
                await self.session.close()
            self.connected = False
            return False

    async def _ws_keepalive(self):
        """Send periodic ping to keep WebSocket connection alive."""
        while self.ws_connected:
            try:
                if not self.ws:
                    self.logger.error("WebSocket connection lost")
                    break
                    
                await self.ws.ping()
                await asyncio.sleep(self.options['ws']['ping_interval'])
            except Exception as e:
                self.logger.error(f"WebSocket keepalive failed: {str(e)}")
                await self._handle_ws_error()
                break

    async def _ws_message_handler(self):
        """Handle incoming WebSocket messages."""
        while self.ws_connected:
            try:
                if not self.ws:
                    self.logger.error("WebSocket connection lost")
                    break
                    
                message = await self.ws.receive()
                
                if message.type == aiohttp.WSMsgType.TEXT:
                    await self.handle_websocket_message(message.data)
                elif message.type == aiohttp.WSMsgType.CLOSED:
                    self.logger.warning("WebSocket connection closed by server")
                    break
                elif message.type == aiohttp.WSMsgType.ERROR:
                    self.logger.error(f"WebSocket connection error: {str(message.data)}")
                    break
                    
            except asyncio.TimeoutError:
                self.logger.warning("WebSocket message timeout")
                continue
            except Exception as e:
                self.logger.error(f"Error handling WebSocket message: {str(e)}")
                await self._handle_ws_error()
                break

    async def handle_websocket_message(self, message: str) -> None:
        """Handle incoming WebSocket messages."""
        try:
            data = json.loads(message)
            if 'topic' not in data:
                self.logger.warning(f"Unhandled WebSocket message: {message}")
                return
            
            topic = data['topic']
            
            # Handle liquidation messages
            if topic.startswith('allLiquidation.'):
                await self._handle_liquidation_message(data)
            else:
                self.logger.debug(f"Unhandled topic: {topic}")
            
        except json.JSONDecodeError as e:
            self.logger.error(f"Failed to decode WebSocket message: {str(e)}")

    async def _handle_liquidation_message(self, message: dict) -> None:
        """Handle liquidation message from WebSocket."""
        try:
            if message.get('type') != 'snapshot':
                return

            ts = message.get('ts')
            liquidation_data = message.get('data', [])
            
            if not liquidation_data:
                return
                
            for liq in liquidation_data:
                liquidation = {
                    'symbol': liq.get('s'),
                    'side': liq.get('S'),
                    'size': float(liq.get('v', 0)),
                    'price': float(liq.get('p', 0)),
                    'timestamp': int(liq.get('T', 0))
                }
                
                self.logger.info(f"Liquidation event: {liquidation}")
                
                # Store liquidation data
                if not hasattr(self, '_liquidations'):
                    self._liquidations = {}
                
                symbol = liquidation['symbol']
                if symbol not in self._liquidations:
                    self._liquidations[symbol] = []
                
                self._liquidations[symbol].append(liquidation)
                
                # Keep only last 24 hours of liquidations
                cutoff = int(time.time() * 1000) - (24 * 60 * 60 * 1000)
                self._liquidations[symbol] = [
                    liq for liq in self._liquidations[symbol]
                    if liq['timestamp'] > cutoff
                ]
                
        except Exception as e:
            self.logger.error(f"Error handling liquidation message: {str(e)}")
            self.logger.debug(f"Message: {message}")
            self.logger.debug(traceback.format_exc())

    async def subscribe_liquidations(self, symbols: List[str]) -> bool:
        """Subscribe to liquidation feed for symbols."""
        try:
            if not self.ws_connected:
                self.logger.error("WebSocket not connected")
                return False

            # Format subscription message
            subscription = {
                "op": "subscribe",
                "args": [f"allLiquidation.{symbol}" for symbol in symbols]
            }
            
            self.logger.info(f"Subscribing to liquidations for symbols: {symbols}")
            
            # Send subscription request
            await self.ws.send_json(subscription)
            
            # Store subscribed symbols
            if not hasattr(self, '_liquidation_subscriptions'):
                self._liquidation_subscriptions = set()
            self._liquidation_subscriptions.update(symbols)
            
            return True
            
        except Exception as e:
            self.logger.error(f"Error subscribing to liquidations: {str(e)}")
            self.logger.debug(traceback.format_exc())
            return False

    def get_recent_liquidations(self, symbol: str, hours: int = 24) -> List[Dict[str, Any]]:
        """Get recent liquidation events for a symbol.
        
        Args:
            symbol: The trading pair symbol
            hours: Number of hours of history to return (default 24)
            
        Returns:
            List of liquidation events
        """
        try:
            if not hasattr(self, '_liquidations') or symbol not in self._liquidations:
                return []
                
            cutoff = int(time.time() * 1000) - (hours * 60 * 60 * 1000)
            return [
                liq for liq in self._liquidations[symbol]
                if liq['timestamp'] > cutoff
            ]
            
        except Exception as e:
            self.logger.error(f"Error getting liquidations for {symbol}: {str(e)}")
            return []

    async def _initialize_subscriptions(self) -> None:
        """Initialize WebSocket subscriptions after connection."""
        try:
            if not self.ws_connected:
                self.logger.error("Cannot initialize subscriptions - WebSocket not connected")
                return

            # Get symbols from config
            symbols = self.config.get('websocket', {}).get('symbols', [])
            if not symbols:
                self.logger.warning("No symbols configured for WebSocket")
                return

            # Subscribe to liquidations
            await self.subscribe_liquidations(symbols)
            
        except Exception as e:
            self.logger.error(f"Error initializing subscriptions: {str(e)}")
            self.logger.debug(traceback.format_exc())

    async def _handle_ws_error(self):
        """Handle WebSocket errors and attempt reconnection."""
        self.ws_connected = False
        
        if self.ws:
            try:
                await self.ws.close()
            except:
                pass
            self.ws = None
            
        # Attempt reconnection
        for attempt in range(self.options['ws']['reconnect_attempts']):
            logger.info(f"Attempting WebSocket reconnection ({attempt + 1}/{self.options['ws']['reconnect_attempts']})")
            if await self.connect_ws():
                # Resubscribe to previous topics
                for topic in self.ws_subscriptions:
                    await self.ws_subscribe(topic)
                return
            await asyncio.sleep(self.options['ws']['reconnect_delay'])
            
        logger.error("Failed to reconnect WebSocket after multiple attempts")

    async def ws_subscribe(self, topic: str, callback: Optional[Callable] = None) -> bool:
        """Subscribe to a WebSocket topic."""
        if not self.ws_connected:
            if not await self.connect_ws():
                return False
                
        try:
            subscribe_message = {
                'op': 'subscribe',
                'args': [topic]
            }
            await self.ws.send(json.dumps(subscribe_message))
            
            if callback:
                self.ws_callbacks[topic] = callback
            self.ws_subscriptions[topic] = True
            
            logger.info(f"Subscribed to WebSocket topic: {topic}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to subscribe to topic {topic}: {str(e)}")
            return False

    async def ws_unsubscribe(self, topic: str) -> bool:
        """Unsubscribe from a WebSocket topic."""
        if not self.ws_connected:
            return True
            
        try:
            unsubscribe_message = {
                'op': 'unsubscribe',
                'args': [topic]
            }
            await self.ws.send(json.dumps(unsubscribe_message))
            
            if topic in self.ws_callbacks:
                del self.ws_callbacks[topic]
            if topic in self.ws_subscriptions:
                del self.ws_subscriptions[topic]
                
            logger.info(f"Unsubscribed from WebSocket topic: {topic}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to unsubscribe from topic {topic}: {str(e)}")
            return False

    async def _initialize_ws_connection(self) -> bool:
        """Initialize WebSocket connection with proper error handling."""
        try:
            if not self._market_type:
                raise ValueError("Market type not set")
            
            ws_url = self.WS_ENDPOINTS[self._market_type]['public']
            self.ws = await self._create_ws_connection(ws_url)
            
            if not self.ws:
                return False
            
            self.ws_connected = True
            self._start_ws_tasks()
            return True
            
        except Exception as e:
            self.logger.error(f"Error initializing WebSocket: {str(e)}")
            return False

    def _create_error_context(self, operation: str, details: Dict[str, Any]) -> ErrorContext:
        """Create error context for operations."""
        return ErrorContext(
            exchange='bybit',
            operation=operation,
            details=details,
            timestamp=int(time.time() * 1000)
        )

    def validate_market_data(self, market_data: Dict[str, Any]) -> bool:
        """Validate market data structure and types.
        
        Args:
            market_data: Dictionary containing market data
            
        Returns:
            bool: True if valid, False otherwise
        """
        try:
            # Check basic structure
            if not isinstance(market_data, dict):
                self.logger.error(f"Market data must be a dictionary, got {type(market_data)}")
                return False
                
            # Required fields and their types
            required_fields = {
                'symbol': str,
                'turnover24h': (int, float),
                'volume24h': (int, float),
                'price': dict,
                'bid': (int, float),
                'ask': (int, float)
            }
            
            # Check required fields
            for field, expected_type in required_fields.items():
                if field not in market_data:
                    self.logger.error(f"Missing required field: {field}")
                    return False
                    
                value = market_data[field]
                if not isinstance(value, expected_type):
                    if isinstance(expected_type, tuple):
                        if not isinstance(value, expected_type[0]) and not isinstance(value, expected_type[1]):
                            self.logger.error(f"Invalid type for {field}: expected {expected_type}, got {type(value)}")
                            return False
                    else:
                        if not isinstance(value, expected_type):
                            self.logger.error(f"Invalid type for {field}: expected {expected_type}, got {type(value)}")
                            return False
            
            # Check price structure
            price = market_data['price']
            required_price_fields = {
                'last': (int, float),
                'high': (int, float),
                'low': (int, float),
                'change_24h': (int, float)
            }
            
            for field, expected_type in required_price_fields.items():
                if field not in price:
                    self.logger.error(f"Missing required price field: {field}")
                    return False
                    
                value = price[field]
                if not isinstance(value, expected_type[0]) and not isinstance(value, expected_type[1]):
                    self.logger.error(f"Invalid type for price.{field}: expected {expected_type}, got {type(value)}")
                    return False
            
            # Validate numeric values
            numeric_fields = [
                ('turnover24h', 0),
                ('volume24h', 0),
                ('bid', 0),
                ('ask', 0),
                ('price.last', 0),
                ('price.high', 0),
                ('price.low', 0)
            ]
            
            for field, min_value in numeric_fields:
                if '.' in field:
                    parent, child = field.split('.')
                    value = market_data[parent][child]
                else:
                    value = market_data[field]
                    
                if value < min_value:
                    self.logger.warning(f"Invalid {field} value: {value} (should be >= {min_value})")
                    # Don't return False here, just warn
            
            return True
            
        except Exception as e:
            self.logger.error(f"Error validating market data: {str(e)}")
            self.logger.debug(traceback.format_exc())
            return False

    def sign(
        self,
        method: str,
        path: str,
        params: Optional[Dict] = None,
        headers: Optional[Dict] = None,
        body: Optional[Dict] = None
    ) -> Tuple[str, Dict, Dict, Dict]:
        """Sign request for private endpoints"""
        api_key = self.credentials.get('apiKey')
        secret = self.credentials.get('secret')
        
        if not api_key or not secret:
            raise AuthenticationError('Missing API credentials')
            
        # Build request data
        timestamp = int(time.time() * 1000)
        headers = headers or {}
        params = params or {}
        body = body or {}
        
        # Add authentication params
        params.update({
            'api_key': api_key,
            'timestamp': timestamp,
            'recv_window': self.options['recvWindow']
        })
        
        # Build signature string
        if method == 'GET':
            signature_string = '&'.join([
                f"{k}={v}" for k, v in sorted(params.items())
            ])
        else:
            signature_string = str(timestamp) + api_key + str(self.options['recvWindow']) + json.dumps(body)
            
        # Generate signature
        signature = hmac.new(
            secret.encode(),
            signature_string.encode(),
            hashlib.sha256
        ).hexdigest()
        
        # Add signature to params
        params['sign'] = signature
        
        # Build URL
        url = f"{self.api_urls['v5']}{path}"
        
        # Add headers
        headers.update({
            'X-BAPI-API-KEY': api_key,
            'X-BAPI-TIMESTAMP': str(timestamp),
            'X-BAPI-RECV-WINDOW': str(self.options['recvWindow']),
            'X-BAPI-SIGN': signature,
            'Content-Type': 'application/json'
        })
        
        return url, params, headers, body
        
    def _handle_errors(self, response: Dict[str, Any]) -> None:
        """Handle Bybit specific errors"""
        if not isinstance(response, dict):
            return
            
        ret_code = str(response.get('retCode', 0))
        if ret_code != '0':
            error_msg = response.get('retMsg', 'Unknown error')
            error_desc = self.ERROR_CODES.get(ret_code, 'Unknown error code')
            
            error_type = None
            if ret_code in ['10007', '10008', '10009']:
                error_type = AuthenticationError
            elif ret_code == '10006':
                error_type = NetworkError
            else:
                error_type = BybitExchangeError
                
            raise error_type(f"Bybit API error {ret_code}: {error_msg} ({error_desc})")
            
    async def fetch_balance(
        self,
        params: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Fetch account balance"""
        try:
            response = await self.private_request(
                'GET',
                '/asset/v3/private/transfer/account-coins/balance/query',
                params=params
            )
            
            self._handle_errors(response)
            
            balances = {}
            for balance in response['result']['balance']:
                currency = balance['coin']
                balances[currency] = {
                    'free': float(balance['availableToWithdraw']),
                    'used': float(balance['locked']),
                    'total': float(balance['walletBalance'])
                }
                
            return {
                'info': response,
                'balances': balances,
                'timestamp': int(time.time() * 1000),
                'datetime': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Error fetching balance: {str(e)}")
            raise
            
    async def create_order(
        self,
        symbol: str,
        type: str,
        side: str,
        amount: float,
        price: Optional[float] = None,
        params: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """Create new order"""
        try:
            self.validate_symbol(symbol)
            
            # Prepare order params
            order = {
                'symbol': symbol,
                'side': side.upper(),
                'orderType': type.upper(),
                'qty': str(amount)
            }
            
            if price:
                order['price'] = str(price)
                
            if params:
                order.update(params)
                
            response = await self.private_request(
                'POST',
                '/v5/order/create',
                body=order
            )
            
            self._handle_errors(response)
            
            return self.parse_order(response['result'])
            
        except Exception as e:
            self.logger.error(f"Error creating order: {str(e)}")
            raise
            
    def parse_order(self, order: Dict[str, Any]) -> Dict[str, Any]:
        """Parse order response to standard format"""
        return {
            'id': order['orderId'],
            'symbol': order['symbol'],
            'type': order['orderType'].lower(),
            'side': order['side'].lower(),
            'price': float(order.get('price', 0)),
            'amount': float(order['qty']),
            'filled': float(order.get('cumExecQty', 0)),
            'remaining': float(order.get('leavesQty', order['qty'])),
            'status': self.parse_order_status(order['orderStatus']),
            'timestamp': int(order['createdTime']),
            'datetime': datetime.fromtimestamp(int(order['createdTime']) / 1000).isoformat(),
            'info': order
        }
        
    def parse_order_status(self, status: str) -> str:
        """Parse order status to standard format"""
        statuses = {
            'Created': 'open',
            'New': 'open', 
            'Rejected': 'rejected',
            'PartiallyFilled': 'open',
            'PartiallyFilledCanceled': 'canceled',
            'Filled': 'closed',
            'Cancelled': 'canceled',
            'Untriggered': 'open',
            'Triggered': 'open',
            'Deactivated': 'canceled'
        }
        return statuses.get(status, 'unknown')

    async def subscribe_to_symbol(self, symbol: str):
        """Subscribe to all relevant feeds for a symbol."""
        try:
            # Subscribe to liquidations via WebSocket
            await self.ws.subscribe_liquidations(symbol)
        except Exception as e:
            self.logger.error(f"Error subscribing to symbol feeds: {str(e)}")

    async def get_recent_liquidations(self, symbol: str) -> List[Dict[str, Any]]:
        """Get recent liquidation events from WebSocket buffer."""
        try:
            return self.ws.get_recent_liquidations(symbol)
        except Exception as e:
            self.logger.error(f"Error fetching liquidations: {str(e)}")
            return []

    async def fetch_exchange_info(self) -> Optional[Dict[str, Any]]:
        """Fetch exchange information including trading rules."""
        try:
            # Make request without decorator arguments
            response = await self._make_request('/v5/market/instruments-info', {'category': 'linear'})
            if response and 'result' in response:
                return response['result']
            return None
        except Exception as e:
            self.logger.error(f"Error fetching exchange info: {str(e)}")
            return None

    async def refresh_market_data(self, force: bool = False) -> bool:
        """Refresh market data if cache is expired or force is True."""
        if not force and time.time() - self._cache_timestamp < self._cache_ttl:
            return True
            
        async with self._data_refresh_lock:
            logger.info("Refreshing market data...")
            return await self.fetch_market_data()

    async def _cleanup(self):
        """Clean up resources."""
        try:
            if hasattr(self, 'session') and self.session:
                await self.session.close()
                self.session = None
            
            if hasattr(self, 'ws') and self.ws:
                await self.ws.close()
                self.ws = None
            
            self.initialized = False
            self.logger.info("Cleaned up Bybit exchange resources")
            
        except Exception as e:
            self.logger.error(f"Error during cleanup: {str(e)}")

    async def close(self) -> None:
        """Close exchange connections."""
        try:
            if hasattr(self, 'session') and self.session:
                await self.session.close()
            if hasattr(self, 'ws') and self.ws:
                await self.ws.close()
        except Exception as e:
            self.logger.error(f"Error closing exchange connections: {str(e)}")

    async def test_connection(self) -> bool:
        """Test API connectivity."""
        max_retries = 3
        retry_delay = 1.0
        
        for attempt in range(max_retries):
            try:
                # Use v5 API endpoint for time
                async with aiohttp.ClientSession() as session:
                    url = f"{self.rest_endpoint}/v5/market/time"
                    async with session.get(url) as response:
                        if response.status == 200:
                            data = await response.json()
                            if data and data.get('retCode') == 0:
                                self.logger.debug("API connection test successful")
                                return True
                            else:
                                error_text = data.get('retMsg', 'Unknown error') if data else 'No response data'
                                self.logger.error(f"API connection test failed: {error_text}")
                        else:
                            self.logger.error(f"API connection test failed: {response.status}")
                            
                        if attempt == max_retries - 1:
                            return False
                            
                        await asyncio.sleep(retry_delay * (attempt + 1))
                        continue
                        
            except Exception as e:
                self.logger.error(f"Connection test failed: {str(e)}")
                if attempt == max_retries - 1:
                    return False
                await asyncio.sleep(retry_delay * (attempt + 1))
                continue
        
        return False

    def _generate_signature(self, params: Dict[str, Any]) -> str:
        """Generate signature for authenticated requests."""
        try:
            # Sort parameters alphabetically
            sorted_params = dict(sorted(params.items()))
            
            # Convert parameters to query string
            query_string = urlencode(sorted_params)
            
            # Create signature
            signature = hmac.new(
                self.api_secret.encode(),
                query_string.encode(),
                hashlib.sha256
            ).hexdigest()
            
            return signature
            
        except Exception as e:
            self.logger.error(f"Error generating signature: {str(e)}")
            raise

    async def validate_credentials(self) -> bool:
        """Validate API credentials are correct and have required permissions."""
        try:
            self.logger.info("Validating Bybit API credentials...")
            
            # Test authentication with a simple API call
            response = await self._make_request('GET', 'v5/account/wallet-balance', {
                'accountType': 'UNIFIED'
            })
            
            if not response or response.get('retCode') != 0:
                self.logger.error(
                    f"API credential validation failed: {response.get('retMsg', 'Unknown error')}"
                )
                return False
            
            self.logger.info("API credentials validated successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Error validating credentials: {str(e)}")
            return False

    async def parse_balance(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """Parse balance response"""
        result = {'info': response}
        for balance in response.get('result', {}).get('list', []):
            currency = balance['coin']
            result[currency] = {
                'free': float(balance.get('free', 0)),
                'used': float(balance.get('locked', 0)),
                'total': float(balance.get('total', 0))
            }
        return result

    async def parse_ohlcv(self, response: Dict[str, Any]) -> List[List[float]]:
        """Parse OHLCV data"""
        ohlcv = []
        for candle in response.get('result', {}).get('list', []):
            ohlcv.append([
                int(candle[0]),  # timestamp
                float(candle[1]),  # open
                float(candle[2]),  # high
                float(candle[3]),  # low
                float(candle[4]),  # close
                float(candle[5])   # volume
            ])
        return ohlcv

    async def parse_orderbook(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """Parse orderbook response into standardized format."""
        try:
            if not response or response.get('retCode') != 0:
                return None
            
            result = response.get('result', {})
            orderbook = {
                'bids': [],
                'asks': [],
                'timestamp': int(result.get('ts', time.time() * 1000))
            }
            
            # Parse bids and asks
            for bid in result.get('b', []):
                orderbook['bids'].append([float(bid[0]), float(bid[1])])
            
            for ask in result.get('a', []):
                orderbook['asks'].append([float(ask[0]), float(ask[1])])
            
            return orderbook
            
        except Exception as e:
            self.logger.error(f"Error parsing orderbook: {str(e)}")
            return None

    async def parse_ticker(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """Parse ticker data"""
        ticker = response.get('result', {})
        return {
            'bid': float(ticker.get('bid', 0)),
            'ask': float(ticker.get('ask', 0)),
            'last': float(ticker.get('last', 0)),
            'volume': float(ticker.get('volume', 0)),
            'open_interest': float(ticker.get('openInterest', 0)),
            'open_interest_value': float(ticker.get('openInterestValue', 0)),
            'funding_rate': float(ticker.get('fundingRate', 0)),
            'next_funding_time': int(ticker.get('nextFundingTime', 0)),
            'mark_price': float(ticker.get('markPrice', 0)),
            'index_price': float(ticker.get('indexPrice', 0))
        }

    async def parse_trades(self, response: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Parse trades data from Bybit API response.
        
        Args:
            response: Raw API response from Bybit
            
        Returns:
            List of standardized trade dictionaries
        """
        trades = []
        try:
            trade_list = response.get('result', {}).get('list', [])
            self.logger.debug(f"Processing {len(trade_list)} raw trades")
            
            # Track validation issues
            validation_issues = defaultdict(int)
            
            for trade in trade_list:
                try:
                    # Extract and validate required fields
                    trade_data = {
                        'id': str(trade.get('execId', '')),
                        'price': float(trade.get('price', 0)),
                        'size': float(trade.get('size', 0)),
                        'side': str(trade.get('side', '')).lower(),
                        'time': int(trade.get('time', 0)),
                        'symbol': trade.get('symbol', ''),
                        'isBlockTrade': bool(trade.get('isBlockTrade', False)),
                        'info': trade  # Store raw trade data
                    }
                    
                    # Validate required fields
                    required_fields = ['id', 'price', 'size', 'side', 'time', 'symbol']
                    missing_fields = [f for f in required_fields if not trade_data.get(f)]
                    if missing_fields:
                        validation_issues['missing_fields'] += 1
                        continue
                    
                    # Validate numeric values with precision checks
                    if not (0 < trade_data['price'] <= 1000000):
                        validation_issues['invalid_price'] += 1
                        continue
                        
                    if not (0 < trade_data['size'] <= 1000000000):
                        validation_issues['invalid_size'] += 1
                        continue
                    
                    # Validate side values
                    if trade_data['side'] not in ['buy', 'sell']:
                        validation_issues['invalid_side'] += 1
                        continue
                    
                    # Validate timestamp (assuming milliseconds)
                    min_valid_ts = 1609459200000  # 2021-01-01
                    max_valid_ts = 2147483648000  # 2038-01-01
                    if not (min_valid_ts <= trade_data['time'] <= max_valid_ts):
                        validation_issues['invalid_timestamp'] += 1
                        continue
                    
                    # Validate symbol format
                    if not re.match(r'^[A-Z0-9]{6,12}(USDT|USD|BTC|ETH)$', trade_data['symbol']):
                        validation_issues['invalid_symbol'] += 1
                        continue
                    
                    trades.append(trade_data)
                    
                except (ValueError, TypeError) as e:
                    validation_issues['parse_error'] += 1
                    continue
            
            # Log validation summary
            if validation_issues:
                self.logger.warning(f"Trade validation issues: {dict(validation_issues)}")
            
            # Log sample trade if available
            if trades:
                sample = {k:v for k,v in trades[0].items() if k != 'info'}
                self.logger.debug(f"Successfully processed {len(trades)}/{len(trade_list)} trades. Sample: {sample}")
            
            return trades
            
        except Exception as e:
            self.logger.error(f"Error parsing trades: {str(e)}")
            self.logger.debug(traceback.format_exc())
            return []

    async def subscribe_ws(self, channels: List[str]) -> None:
        """Subscribe to websocket channels"""
        if not self.ws:
            await self.connect_ws()
        for channel in channels:
            await self.ws_subscribe(channel)

    async def health_check(self) -> bool:
        """Verify exchange connection health."""
        try:
            # Test server time endpoint
            response = await self._make_request('GET', '/v5/market/time', {})
            
            if not isinstance(response, dict):
                self.logger.error("Invalid response format")
                return False
            
            if response.get('retCode') == 0:
                self.logger.debug("Health check successful")
                return True
            
            self.logger.error(f"Health check failed with response: {response}")
            return False
            
        except Exception as e:
            self.logger.error(f"Health check failed with exception: {str(e)}")
            self.logger.debug("Full exception details:", exc_info=True)
            return False

    async def subscribe_market_data(self, symbol: str):
        """Subscribe to market data streams based on config."""
        try:
            if not self.ws_config.get('enabled', False):
                self.logger.warning("WebSocket is not enabled in config")
                return
                
            # Use channels from config
            channels = []
            if 'trade' in self.ws_channels:
                channels.append(f"trades.{symbol}")
            if 'orderbook' in self.ws_channels:
                channels.append(f"orderbook.50.{symbol}")
            if 'kline' in self.ws_channels:
                channels.append(f"kline.1.{symbol}")  # Use '1' instead of '1m'
                
            # Always subscribe to liquidation feed (required for sentiment analysis)
            channels.append(f"liquidation.{symbol}")
            
            # Add additional data streams
            channels.extend([
                f"tickers.{symbol}"
            ])
            
            for channel in channels:
                await self.ws_subscribe(channel)
                self.logger.debug(f"Subscribed to {channel}")
                
                # Register specific handler for liquidation data
                if channel.startswith('liquidation.'):
                    self.ws.on_message(channel, self._handle_liquidation_update)
                
        except Exception as e:
            self.logger.error(f"Failed to subscribe to market data: {str(e)}")
            raise

    async def _handle_liquidation_update(self, message: Dict[str, Any]) -> None:
        """Handle incoming liquidation data from WebSocket."""
        try:
            if not message or 'data' not in message:
                return
                
            data = message['data']
            symbol = data.get('symbol')
            
            if not symbol:
                return
                
            liquidation = {
                'symbol': symbol,
                'side': data.get('side', '').lower(),
                'price': float(data.get('price', 0)),
                'size': float(data.get('size', 0)),
                'timestamp': int(data.get('time', time.time() * 1000))
            }
            
            # Store liquidation data
            if not hasattr(self, 'market_data'):
                self.market_data = {}
            if symbol not in self.market_data:
                self.market_data[symbol] = {'sentiment': {'liquidations': []}}
            
            self.market_data[symbol]['sentiment']['liquidations'].append(liquidation)
            
            # Keep only recent liquidations (last 24 hours)
            cutoff = int(time.time() * 1000) - (24 * 60 * 60 * 1000)
            self.market_data[symbol]['sentiment']['liquidations'] = [
                liq for liq in self.market_data[symbol]['sentiment']['liquidations']
                if liq['timestamp'] > cutoff
            ]
            
            self.logger.debug(f"Processed liquidation: {liquidation}")
            
        except Exception as e:
            self.logger.error(f"Error processing liquidation update: {str(e)}")
            self.logger.debug(f"Raw message: {message}")

    async def _check_rate_limit(self, endpoint: str, category: str = 'linear') -> None:
        """Check rate limit for endpoint and category."""
        async with self._rate_limit_lock:
            now = time.time()
            
            # Check composite market_data limit first if applicable
            if endpoint == 'market_data':
                market_data_bucket = self._rate_limit_buckets.setdefault('market_data', [])
                market_data_limit = self.RATE_LIMITS['endpoints']['market_data']
                
                # Clean expired timestamps
                market_data_bucket[:] = [ts for ts in market_data_bucket if ts > now - market_data_limit['per_second']]
                
                # Check market_data limit
                if len(market_data_bucket) >= market_data_limit['requests']:
                    wait_time = market_data_bucket[0] + market_data_limit['per_second'] - now
                    if wait_time > 0:
                        self.logger.debug(f"Market data composite rate limit hit, waiting {wait_time:.2f}s")
                        await asyncio.sleep(wait_time)
                        await self._check_rate_limit(endpoint, category)
                        return
                
                market_data_bucket.append(now)
                return
            
            # Check category limit first
            category_bucket = self._rate_limit_buckets.setdefault(f'category_{category}', [])
            category_limit = self.RATE_LIMITS['category'][category]
            
            # Clean expired timestamps
            category_bucket[:] = [ts for ts in category_bucket if ts > now - category_limit['per_second']]
            
            # Check category limit
            if len(category_bucket) >= category_limit['requests']:
                wait_time = category_bucket[0] + category_limit['per_second'] - now
                if wait_time > 0:
                    self.logger.debug(f"Category {category} rate limit hit, waiting {wait_time:.2f}s")
                    await asyncio.sleep(wait_time)
                    await self._check_rate_limit(endpoint, category)  # Recursive check
                    return
            
            # Check endpoint limit
            endpoint_bucket = self._rate_limit_buckets.setdefault(endpoint, [])
            endpoint_limit = self.RATE_LIMITS['endpoints'][endpoint]
            
            # Clean expired timestamps
            endpoint_bucket[:] = [ts for ts in endpoint_bucket if ts > now - endpoint_limit['per_second']]
            
            # Check endpoint limit
            if len(endpoint_bucket) >= endpoint_limit['requests']:
                wait_time = endpoint_bucket[0] + endpoint_limit['per_second'] - now
                if wait_time > 0:
                    self.logger.debug(f"Endpoint {endpoint} rate limit hit, waiting {wait_time:.2f}s")
                    await asyncio.sleep(wait_time)
                    await self._check_rate_limit(endpoint, category)
                    return
            
            # Update buckets
            category_bucket.append(now)
            endpoint_bucket.append(now)

    async def fetch_market_data(self, symbol: str) -> Dict[str, Any]:
        """Fetch comprehensive market data for a symbol with rate limiting."""
        try:
            # Check category-level rate limit first
            await self._check_rate_limit('market_data', category='linear')
            
            # Create tasks with individual rate limits
            tasks = []
            
            async def fetch_with_retry(endpoint: str, fetch_func: Callable, *args, **kwargs) -> Any:
                max_retries = 3
                retry_delay = 1.0
                last_error = None
                
                for attempt in range(max_retries):
                    try:
                        await self._check_rate_limit(endpoint, category='linear')
                        result = await fetch_func(*args, **kwargs)
                        if result is None:
                            raise ValueError(f"Empty result from {endpoint}")
                        return result
                    except RateLimitError as e:
                        last_error = e
                        if attempt == max_retries - 1:
                            break
                        retry_after = getattr(e, 'retry_after', retry_delay * (attempt + 1))
                        self.logger.warning(f"Rate limit hit for {endpoint}, waiting {retry_after}s")
                        await asyncio.sleep(retry_after)
                    except Exception as e:
                        last_error = e
                        if attempt == max_retries - 1:
                            break
                        self.logger.error(f"Error fetching {endpoint}: {str(e)}")
                        await asyncio.sleep(retry_delay * (attempt + 1))
                
                # If we get here, all retries failed
                self.logger.error(f"All retries failed for {endpoint}: {str(last_error)}")
                raise last_error or Exception(f"Failed to fetch {endpoint}")
            
            # Add tasks with retries
            tasks.extend([
                fetch_with_retry('ticker', self.fetch_ticker, symbol),
                fetch_with_retry('orderbook', self.fetch_order_book, symbol),
                fetch_with_retry('trades', self.fetch_trades, symbol),
                fetch_with_retry('kline', self._fetch_all_timeframes, symbol),
                fetch_with_retry('long_short_ratio', self._fetch_long_short_ratio, symbol),
                fetch_with_retry('risk_limits', self._fetch_risk_limits, symbol)
            ])
            
            # Execute all fetches concurrently with timeout
            results = await asyncio.gather(*tasks, return_exceptions=True)
            ticker, orderbook, trades, ohlcv, long_short_ratio, risk_limits = results
            
            # Check for exceptions in results
            for i, (result, endpoint) in enumerate(zip(results, ['ticker', 'orderbook', 'trades', 'kline', 'long_short_ratio', 'risk_limits'])):
                if isinstance(result, Exception):
                    self.logger.error(f"Error in {endpoint} fetch: {str(result)}")
            
            # Structure market data with proper typing and structure
            market_data = {
                'symbol': symbol,
                'timestamp': int(time.time() * 1000),
                'ticker': ticker if not isinstance(ticker, Exception) else {},
                'orderbook': orderbook if not isinstance(orderbook, Exception) else {'bids': [], 'asks': []},
                'trades': trades if not isinstance(trades, Exception) else [],
                'ohlcv': ohlcv if not isinstance(ohlcv, Exception) else {},
                'sentiment': {
                    'long_short_ratio': (
                        long_short_ratio['long'] / (long_short_ratio['short'] + long_short_ratio['long']) 
                        if long_short_ratio and not isinstance(long_short_ratio, Exception)
                        else None
                    ),
                    'liquidations': [],  # Will be populated via WebSocket
                    'funding_rate': float(ticker.get('funding_rate', 0)) if not isinstance(ticker, Exception) else 0.0,
                    'open_interest': float(ticker.get('open_interest', 0)) if not isinstance(ticker, Exception) else 0.0
                },
                'risk_limit': risk_limits if not isinstance(risk_limits, Exception) else {},
                'metadata': {
                    'exchange': 'bybit',
                    'market_type': 'linear',
                    'quote_currency': 'USDT',
                    'fetch_timestamp': int(time.time() * 1000),
                    'success': {
                        'ticker': not isinstance(ticker, Exception),
                        'orderbook': not isinstance(orderbook, Exception),
                        'trades': not isinstance(trades, Exception),
                        'ohlcv': not isinstance(ohlcv, Exception),
                        'long_short_ratio': not isinstance(long_short_ratio, Exception),
                        'risk_limits': not isinstance(risk_limits, Exception)
                    }
                }
            }
            
            # Add fallbacks for critical fields
            market_data.setdefault('sentiment', {}).setdefault('long_short_ratio', 0.5)
            market_data.setdefault('risk_limit', {}).setdefault('list', [])
            
            # Add data freshness check
            if 'fetch_timestamp' in market_data.get('metadata', {}):
                age = time.time() - (market_data['metadata']['fetch_timestamp'] / 1000)
                if age > 300:  # 5 minutes
                    self.logger.warning(f"Stale market data for {symbol} ({age:.1f}s old)")
            
            # Log data structure before validation
            self.logger.debug("Market data structure before validation:")
            self.logger.debug(f"Sentiment data: {market_data['sentiment']}")
            self.logger.debug(f"Risk limits: {market_data['risk_limit']}")
            
            # Validate market data structure
            if not self.validate_market_data(market_data):
                self.logger.error(f"Invalid market data structure for {symbol}")
                return {}
            
            # Get long/short ratio
            ls_ratio = await self.fetch_long_short_ratio(symbol)
            if ls_ratio and 'list' in ls_ratio.get('result', {}):
                market_data['long_short_ratio'] = {
                    'buy_ratio': float(ls_ratio['result']['list'][0]['buyRatio']),
                    'sell_ratio': float(ls_ratio['result']['list'][0]['sellRatio']),
                    'timestamp': int(ls_ratio['result']['list'][0]['timestamp'])
                }
            
            return market_data
            
        except Exception as e:
            self.logger.error(f"Error fetching market data for {symbol}: {str(e)}")
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
            return {}
    async def _fetch_with_rate_limit(self, endpoint: str, fetch_func: Callable, *args, **kwargs) -> Any:
        """Execute fetch function with rate limiting."""
        await self._check_rate_limit(endpoint)
        return await fetch_func(*args, **kwargs)

    async def _fetch_all_timeframes(self, symbol: str) -> Dict[str, pd.DataFrame]:
        """Fetch OHLCV data for all required timeframes."""
        try:
            # Define timeframe mapping - use Bybit's format but store with standard names
            timeframes = {
                '1': 'base',    # 1 minute - store as 'base'
                '5': 'ltf',     # 5 minutes
                '30': 'mtf',    # 30 minutes
                '240': 'htf'    # 4 hours (240 minutes)
            }
            
            ohlcv_data = {}
            
            # Fetch each timeframe with rate limiting
            for bybit_interval, tf_name in timeframes.items():
                max_retries = 3
                retry_delay = 1.0
                
                for attempt in range(max_retries):
                    try:
                        # Check rate limit before each OHLCV fetch
                        await self._check_rate_limit('kline', category='linear')
                        
                        self.logger.debug(f"Fetching {bybit_interval} interval ({tf_name}) data for {symbol}")
                        candles = await self._fetch_ohlcv(symbol, bybit_interval)
                        
                        if not candles:
                            self.logger.error(f"No candles returned for {symbol} @ {bybit_interval}")
                            if attempt == max_retries - 1:
                                raise ValueError(f"Failed to fetch candles for {bybit_interval}")
                            await asyncio.sleep(retry_delay * (attempt + 1))
                            continue
                        
                        # Convert to DataFrame with error handling
                        try:
                            df = pd.DataFrame(
                                candles,
                                columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']
                            )
                            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
                            df.set_index('timestamp', inplace=True)
                            
                            # Validate DataFrame
                            if df.empty:
                                raise ValueError("Empty DataFrame")
                            if df.isnull().values.any():
                                raise ValueError("DataFrame contains null values")
                            
                            ohlcv_data[tf_name] = df
                            self.logger.debug(f"Successfully fetched {len(df)} candles for {tf_name}")
                            break
                            
                        except Exception as e:
                            self.logger.error(f"Error processing candles for {symbol} @ {bybit_interval}: {str(e)}")
                            if attempt == max_retries - 1:
                                raise
                            await asyncio.sleep(retry_delay * (attempt + 1))
                            continue
                            
                    except RateLimitError as e:
                        if attempt == max_retries - 1:
                            raise
                        retry_after = getattr(e, 'retry_after', retry_delay * (attempt + 1))
                        self.logger.warning(f"Rate limit hit for {bybit_interval}, waiting {retry_after}s")
                        await asyncio.sleep(retry_after)
                        continue
                        
                    except Exception as e:
                        self.logger.error(f"Error fetching {bybit_interval} interval: {str(e)}")
                        if attempt == max_retries - 1:
                            raise
                        await asyncio.sleep(retry_delay * (attempt + 1))
                        continue
            
            # Verify all timeframes were fetched
            expected_timeframes = {'base', 'ltf', 'mtf', 'htf'}
            missing_timeframes = expected_timeframes - set(ohlcv_data.keys())
            if missing_timeframes:
                self.logger.error(f"Missing timeframes after fetch: {missing_timeframes}")
                raise ValueError(f"Failed to fetch all required timeframes: {missing_timeframes}")
            
            return ohlcv_data
            
        except Exception as e:
            self.logger.error(f"Error fetching timeframes for {symbol}: {str(e)}")
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
            raise

    async def _fetch_ohlcv(self, symbol: str, interval: str) -> List[List[Any]]:
        """Fetch OHLCV data for a specific interval."""
        try:
            self.logger.debug(f"Making OHLCV request for {symbol} @ {interval}")
            response = await self._make_request('GET', '/v5/market/kline', {
                'category': 'linear',
                'symbol': symbol,
                'interval': interval,
                'limit': 200  # Maximum allowed by Bybit
            })
            
            if not response or response.get('retCode') != 0:
                self.logger.error(f"Failed to fetch OHLCV data: {response}")
                return []
            
            # Extract and return candles
            candles = response.get('result', {}).get('list', [])
            if not candles:
                self.logger.warning(f"No candles returned for {symbol} @ {interval}")
            else:
                self.logger.debug(f"Fetched {len(candles)} candles for {symbol} @ {interval}")
            
            return candles
            
        except Exception as e:
            self.logger.error(f"Error in _fetch_ohlcv: {str(e)}")
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
            return []

    async def _subscribe_to_liquidations(self, symbol: str) -> None:
        """Subscribe to liquidation feed for a symbol."""
        try:
            # Subscribe to liquidation topic
            topic = f"liquidation.{symbol}"
            await self.ws.subscribe([topic])
            self.logger.info(f"Subscribed to liquidation feed for {symbol}")
            
            # Register message handler
            self.ws.on_message(topic, self._handle_liquidation_update)
            
        except Exception as e:
            self.logger.error(f"Failed to subscribe to liquidation feed: {str(e)}")

    async def _process_market_data(self, symbol: str) -> Dict[str, Any]:
        """Process and combine all market data.
        
        Args:
            symbol: Trading pair symbol
            
        Returns:
            Dict containing processed market data including trades and sentiment
        """
        try:
            market_data = {
                'symbol': symbol,
                'timestamp': int(time.time() * 1000),
                'timeframes': {},  # Will be populated with candle data
                'trades': [],
                'orderbook': {},
                'sentiment': {
                    'liquidations': [],
                    'funding_rate': None,
                    'long_short_ratio': None
                },
                'ticker': {},
                'risk_limits': {}  # Required by validation
            }
            
            # Process trades
            trades = await self._fetch_recent_trades(symbol)
            if trades:
                processed_trades = []
                for trade in trades:
                    if all(k in trade for k in ['execId', 'price', 'size', 'side', 'time']):
                        processed_trades.append({
                            'id': str(trade['execId']),  # Single point of transformation
                            'price': float(trade['price']),
                            'size': float(trade['size']),
                            'side': str(trade['side']).lower(),
                            'time': int(trade['time'])
                        })
                market_data['trades'] = processed_trades
                
            # Get timeframes data
            for interval in ['1', '5', '30', '240']:
                candles = await self._fetch_klines(symbol, interval)
                if candles:
                    market_data['timeframes'][interval] = candles
                    
            # Get orderbook data
            orderbook = await self.fetch_order_book(symbol)
            if orderbook:
                market_data['orderbook'] = orderbook
                
            # Get ticker data
            ticker = await self._fetch_ticker(symbol) 
            if ticker:
                market_data['ticker'] = ticker
                
            return market_data
                
        except Exception as e:
            self.logger.error(f"Error processing market data for {symbol}: {str(e)}", exc_info=True)
            return {}

    def _validate_config(self, config: Dict[str, Any]) -> bool:
        """Validate exchange configuration."""
        try:
            # Log the config structure for debugging
            self.logger.debug(f"Config keys: {list(config.keys())}")
            
            # Check required keys directly since we're already getting Bybit config
            required_keys = ['enabled', 'api_credentials', 'rest_endpoint', 'websocket']
            missing_keys = [key for key in required_keys if key not in config]
            if missing_keys:
                self.logger.error(f"Missing required Bybit config keys: {missing_keys}")
                return False
            
            # Validate API credentials
            credentials = config.get('api_credentials', {})
            if not credentials.get('api_key') or not credentials.get('api_secret'):
                self.logger.error("Missing API credentials")
                return False
            
            # Validate rate limits
            rate_limits = config.get('rate_limits', {})
            if not rate_limits.get('requests_per_second') or not rate_limits.get('requests_per_minute'):
                self.logger.warning("Missing rate limit configuration, using defaults")
            
            # Validate websocket config if enabled
            ws_config = config.get('websocket', {})
            if ws_config.get('enabled'):
                required_ws_keys = ['mainnet_endpoint', 'channels']
                missing_ws_keys = [key for key in required_ws_keys if key not in ws_config]
                if missing_ws_keys:
                    self.logger.error(f"Missing required websocket config keys: {missing_ws_keys}")
                    return False
                
            return True
            
        except Exception as e:
            self.logger.error(f"Error validating config: {str(e)}", exc_info=True)
            return False

    async def get_markets(self) -> List[Dict[str, Any]]:
        """Get comprehensive market information combining static and dynamic data.
        
        Returns:
            List of market dictionaries containing complete market information
        """
        try:
            # Get static market info
            symbols = await self.fetch_market_symbols()
            
            # Get dynamic market info
            tickers = await self.fetch_market_tickers()
            
            # Combine the information
            markets = {}
            
            # Process symbols
            if isinstance(symbols, dict) and 'result' in symbols:
                symbols = symbols['result'].get('list', [])
            elif not isinstance(symbols, list):
                symbols = []
                
            for symbol in symbols:
                if isinstance(symbol, dict):
                    markets[symbol.get('symbol')] = symbol
                    
            # Process tickers
            if isinstance(tickers, dict) and 'result' in tickers:
                tickers = tickers['result'].get('list', [])
            elif not isinstance(tickers, list):
                tickers = []
                
            for ticker in tickers:
                if isinstance(ticker, dict):
                    symbol = ticker.get('symbol')
                    if symbol:
                        if symbol in markets:
                            markets[symbol].update(ticker)
                        else:
                            markets[symbol] = ticker
                    
            # Convert to list and ensure consistent format
            result = []
            for symbol, data in markets.items():
                try:
                    processed_market = {
            'symbol': symbol,
                        'active': True,  # If it's in tickers, it's trading
                        'turnover24h': float(data.get('turnover24h', 0)),
                        'volume24h': float(data.get('volume24h', 0)),
                            'price': {
                            'last': float(data.get('lastPrice', 0)),
                            'high': float(data.get('highPrice24h', 0)),
                            'low': float(data.get('lowPrice24h', 0)),
                            'change_24h': float(data.get('price24hPcnt', 0))
                        },
                        'bid': float(data.get('bid1Price', 0)),
                        'ask': float(data.get('ask1Price', 0)),
                        'info': data
                    }
                    result.append(processed_market)
                except (ValueError, TypeError) as e:
                    self.logger.warning(f"Error processing market {symbol}: {e}")
                    continue
                    
            self.logger.info(f"Successfully fetched {len(result)} complete market records")
            return result
            
        except Exception as e:
            self.logger.error(f"Error getting complete market data: {str(e)}")
            return []


    async def fetch_market_tickers(self) -> List[Dict[str, Any]]:
        """Fetch market information with current prices and volumes.
        
        Returns:
            List of market dictionaries containing current market data
        """
        try:
            self.logger.debug("Fetching market tickers from Bybit V5 API...")
            response = await self._make_request('GET', '/v5/market/tickers', {
                'category': 'linear'
            })
            
            if not response:
                self.logger.error("Empty response from tickers endpoint")
                return []
                
            if 'retCode' in response and response['retCode'] != 0:
                self.logger.error(f"API error: {response.get('retMsg', 'Unknown error')}")
                return []
                
            if 'result' not in response:
                self.logger.error(f"Missing 'result' in response. Response keys: {list(response.keys())}")
                return []
                
            result = response['result']
            if not isinstance(result, dict):
                self.logger.error(f"Invalid result type: {type(result)}")
                return []
                
            if 'list' not in result:
                self.logger.error(f"Missing 'list' in result. Result keys: {list(result.keys())}")
                return []
                
            ticker_list = result['list']
            if not ticker_list:
                self.logger.warning("Empty ticker list received")
                return []
                
            self.logger.debug(f"Processing {len(ticker_list)} market tickers")
            
            # Initialize quality metrics
            quality_metrics = {
                'total_count': len(ticker_list),
                'processed_count': 0,
                'valid_count': 0,
                'invalid_count': 0,
                'filtered_symbols': [],
                'total_volume': 0.0,
                'total_turnover': 0.0
            }
            
            markets = []
            for idx, market in enumerate(ticker_list):
                try:
                    quality_metrics['processed_count'] += 1
                    
                    if not isinstance(market, dict):
                        self.logger.warning(f"Invalid market data type: {type(market)}")
                        quality_metrics['invalid_count'] += 1
                        continue
                        
                    # Log raw market data for debugging (first few entries)
                    if idx < 3:
                        self.logger.debug(
                            "Market sample:\n"
                            f"Keys: {list(market.keys())}\n"
                            f"Types: {{symbol: {type(market.get('symbol'))}, turnover24h: {type(market.get('turnover24h'))}}}\n"
                            f"Snippet: {{symbol: {market.get('symbol')}, turnover24h: {str(market.get('turnover24h'))[:15]}...}}"
                        )
                    
                    # Safe numeric conversion function
                    def safe_float(value, default=0.0):
                        if value is None:
                            return default
                        try:
                            # Remove any commas and convert to float
                            cleaned = str(value).replace(',', '')
                            return float(cleaned)
                        except (ValueError, TypeError):
                            self.logger.warning(f"Could not convert {value} to float, using default {default}")
                            return default
                    
                    # Process market data with safe conversion
                    processed_market = {
                        'symbol': market['symbol'],
                        'active': True,  # If it's in tickers, it's trading
                        'turnover24h': safe_float(market.get('turnover24h')),
                        'price': {
                            'last': safe_float(market.get('lastPrice')),
                            'high': safe_float(market.get('highPrice24h')),
                            'low': safe_float(market.get('lowPrice24h')),
                            'change_24h': safe_float(market.get('price24hPcnt'))
                        },
                        'volume24h': safe_float(market.get('volume24h')),
                        'bid': safe_float(market.get('bid1Price')),
                        'ask': safe_float(market.get('ask1Price')),
                        'info': market
                    }
                    
                    # Add before validation checks:
                    try:
                        processed_market['volume24h'] = float(processed_market['volume24h'])
                        processed_market['turnover24h'] = float(processed_market['turnover24h'])
                    except ValueError as e:
                        self.logger.error(f"Invalid numeric value in market data: {e}")
                        quality_metrics['invalid_count'] += 1
                        continue
                    
                    # Then perform validation checks...
                    validation_checks = [
                        ('symbol_format', bool(re.match(r'^[A-Z0-9]{1,}(USDT)$', processed_market['symbol']))),
                        ('volume24h', processed_market['volume24h'] >= self.config.get('market_data', {}).get('validation', {}).get('volume', {}).get('min_value', 0)),
                        ('turnover24h', processed_market['turnover24h'] >= self.config.get('market_data', {}).get('validation', {}).get('turnover', {}).get('min_value', 0))
                    ]
                    
                    # Check all validation criteria
                    is_valid = True
                    for field, check in validation_checks:
                        if not check:
                            is_valid = False
                            self.logger.debug(f"Symbol {processed_market['symbol']} failed validation: {field}")
                            break
                    
                    if not is_valid:
                        quality_metrics['invalid_count'] += 1
                        quality_metrics['filtered_symbols'].append({
                            'symbol': processed_market['symbol'],
                            'turnover24h': processed_market['turnover24h'],
                            'volume24h': processed_market['volume24h']
                        })
                        continue
                    
                    # Update quality metrics
                    quality_metrics['valid_count'] += 1
                    quality_metrics['total_volume'] += processed_market['volume24h']
                    quality_metrics['total_turnover'] += processed_market['turnover24h']
                    
                    # Add to validation_checks
                    symbol_valid = bool(re.match(r'^[A-Z0-9]{1,}(USDT)$', processed_market['symbol']))
                    validation_checks.append(('symbol_format', symbol_valid))
                    
                    markets.append(processed_market)
                    
                except (KeyError, ValueError) as e:
                    self.logger.error(f"Error processing market {market.get('symbol', 'unknown')}: {e}")
                    self.logger.debug(f"Problematic market data: {market}")
                    quality_metrics['invalid_count'] += 1
                    continue
            
            # Log quality metrics
            self.logger.info(
                f"Market Data Quality Report:\n"
                f"Total Markets: {quality_metrics['total_count']}\n"
                f"Valid Markets: {quality_metrics['valid_count']}\n"
                f"Invalid/Filtered: {quality_metrics['invalid_count']}\n"
                f"Total Volume: ${quality_metrics['total_volume']:,.2f}\n"
                f"Total Turnover: ${quality_metrics['total_turnover']:,.2f}"
            )
            
            # Log filtered symbols (up to 10)
            if quality_metrics['filtered_symbols']:
                filtered_sample = quality_metrics['filtered_symbols'][:10]
                filtered_log = "\nFiltered Symbols Sample:\n" + "\n".join(
                    f"{s['symbol']}: Vol=${s['volume24h']:,.2f} Turn=${s['turnover24h']:,.2f}"
                    for s in filtered_sample
                )
                if len(quality_metrics['filtered_symbols']) > 10:
                    filtered_log += f"\n...and {len(quality_metrics['filtered_symbols']) - 10} more"
                self.logger.debug(filtered_log)
            
            self.logger.info(f"Successfully processed {len(markets)} valid market records out of {len(ticker_list)} total")
            return markets
            
        except Exception as e:
            self.logger.error(f"Error fetching market tickers: {str(e)}")
            self.logger.debug(traceback.format_exc())
            return []

    async def _get_ws_url(self) -> str:
        """Get WebSocket URL based on configuration."""
        try:
            # Get base URL from config
            base_url = self.config.get('ws_url', 'wss://stream.bybit.com')
            
            # Add API version path
            url = f"{base_url}/v5"
            
            # Add public/linear path
            if not url.endswith('/public/linear'):
                url = f"{url}/public/linear"
                
            self.logger.debug(f"Using WebSocket URL: {url}")
            return url
            
        except Exception as e:
            self.logger.error(f"Error constructing WebSocket URL: {str(e)}")
            raise

    def _get_symbol_string(self, symbol: Union[str, dict]) -> str:
        """Extract symbol string from either string or symbol dict.
        
        Args:
            symbol: Symbol string or dictionary
            
        Returns:
            Symbol string
            
        Raises:
            ValueError: If symbol is invalid
        """
        if isinstance(symbol, dict):
            if 'symbol' not in symbol:
                raise ValueError("Invalid symbol dictionary - missing 'symbol' key")
            return symbol['symbol']
        return str(symbol)

    async def fetch_ohlcv(self, symbol: Union[str, dict], timeframe: str = '1m', limit: int = 1000) -> List[dict]:
        """Fetch OHLCV data with symbol validation.
        
        Args:
            symbol: Symbol string or dictionary
            timeframe: Timeframe string
            limit: Number of candles to fetch
            
        Returns:
            List of OHLCV data
        """
        symbol_str = self._get_symbol_string(symbol)
        params = {
            'category': 'linear',
            'symbol': symbol_str,
            'interval': timeframe,
            'limit': limit
        }
        return await self._make_request('GET', '/v5/market/kline', params)

    async def get_orderbook(self, symbol: Union[str, dict], limit: Optional[int] = None) -> Dict[str, Any]:
        """Get orderbook with symbol validation.
        
        Args:
            symbol: Symbol string or dictionary
            limit: Orderbook depth limit
            
        Returns:
            Orderbook data
        """
        symbol_str = self._get_symbol_string(symbol)
        params = {
            'category': 'linear',
            'symbol': symbol_str
        }
        if limit:
            params['limit'] = limit
        return await self._make_request('GET', '/v5/market/orderbook', params)

    async def fetch_trades(self, symbol: Union[str, dict], since: Optional[int] = None, limit: Optional[int] = None, params={}) -> List[Dict[str, Any]]:
        """Fetch recent trades with symbol validation.
        
        Args:
            symbol: Symbol string or dictionary
            since: Timestamp to fetch trades from
            limit: Number of trades to fetch
            params: Additional parameters
            
        Returns:
            List of trades
        """
        symbol_str = self._get_symbol_string(symbol)
        request_params = {
            'category': 'linear',
            'symbol': symbol_str
        }
        if limit:
            request_params['limit'] = limit
        if since:
            request_params['startTime'] = since
            
        request_params.update(params)
        return await self._make_request('GET', '/v5/market/recent-trade', request_params)

    async def fetch_order_book(self, symbol: str, limit: int = 100) -> dict:
        """Fetch order book for a specific symbol."""
        try:
            response = await self.session.get(
                url=f"{self.api_url}/v5/market/orderbook",
                params={
                    "category": "linear",
                    "symbol": symbol,
                    "limit": limit
                }
            )
            data = await response.json()
            
            if data.get("retCode") != 0:
                self.logger.error(f"Order book fetch failed: {data.get('retMsg')}")
                return {"bids": [], "asks": []}

            orderbook = data["result"]
            return {
                "bids": [[float(b[0]), float(b[1])] for b in orderbook.get("b", [])],
                "asks": [[float(a[0]), float(a[1])] for a in orderbook.get("a", [])]
            }
            
        except Exception as e:
            self.logger.error(f"Error fetching order book: {str(e)}")
            return {"bids": [], "asks": []}

class BybitWebSocket:
    """WebSocket client for Bybit exchange."""
    
    def __init__(self, config: Dict[str, Any], logger: logging.Logger):
        self.config = config
        self.logger = logger
        self.ws = None
        self.session = None
        self.connected = False
        self._message_handlers = {}
        
    async def connect(self) -> bool:
        """Connect to WebSocket."""
        try:
            if self.connected:
                return True
                
            # Get WebSocket URL from config
            ws_config = self.config.get('websocket', {})
            if self.config.get('testnet', False):
                ws_url = ws_config.get('testnet_endpoint', 'wss://stream-testnet.bybit.com/v5/public/linear')
            else:
                ws_url = ws_config.get('mainnet_endpoint', 'wss://stream.bybit.com/v5/public/linear')
                
            # Ensure protocol prefix
            if not ws_url.startswith('wss://'):
                ws_url = f"wss://{ws_url.lstrip('/')}"
                
            self.logger.debug(f"Connecting to WebSocket URL: {ws_url}")
            
            # Create session and connect
            timeout = aiohttp.ClientTimeout(total=10)
            self.session = aiohttp.ClientSession(timeout=timeout)
            self.ws = await self.session.ws_connect(
                ws_url,
                autoclose=False,
                heartbeat=30
            )
            
            self.connected = True
            self.logger.info("WebSocket connected successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"WebSocket connection failed: {str(e)}")
            if self.session:
                await self.session.close()
            self.session = None
            self.ws = None
            self.connected = False
            return False
            
    async def subscribe(self, channels: List[str]) -> bool:
        """Subscribe to channels."""
        try:
            if not self.connected:
                if not await self.connect():
                    return False
                    
            msg = {
                "op": "subscribe",
                "args": channels
            }
            await self.ws.send_json(msg)
            return True
            
        except Exception as e:
            self.logger.error(f"Subscription failed: {str(e)}")
            return False
            
    def on_message(self, channel: str, callback: Callable) -> None:
        """Register message handler for channel."""
        self._message_handlers[channel] = callback

    async def close(self) -> None:
        """Close WebSocket connection."""
        if self.ws:
            await self.ws.close()
        if self.session:
            await self.session.close()
        self.connected = False
        self.ws = None
        self.session = None
    
if __name__ == "__main__":
    raise RuntimeError("This module should not be executed directly")
    
def init():
    # Initialization logic here
    pass
    